{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlv7IfhFQhsv"
      },
      "source": [
        "# Import thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T-mOljzdcIZL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\SeminarDS\\CodeGeneratorProject\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, Iterator\n",
        "from torchtext.legacy import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1UTpnAaSUlp"
      },
      "source": [
        "## Đọc dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wYRncG2sPvbS"
      },
      "outputs": [],
      "source": [
        "f = open(\"data.txt\", \"r\", encoding='utf-8')\n",
        "file_lines = f.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbhPC2wnSbOA"
      },
      "source": [
        "Ta sẽ sử dụng bộ dữ liệu được thu thập bởi TSAI để huấn luyện mô hình. Bộ dữ liệu bao gồm gần 5000 dữ liệu bao gồm câu hỏi tiếng Anh và đoạn code Python tương ứng.\n",
        "\n",
        "Cấu trúc file dữ liệu như sau:\n",
        "\n",
        "```\n",
        "# Câu hỏi 1\n",
        "\n",
        "<Python Code 1>\n",
        "\n",
        "# Câu hỏi 2\n",
        "\n",
        "<Python Code 2>\n",
        "\n",
        "# Câu hỏi 3\n",
        "\n",
        "<Python Code 3>\n",
        "\n",
        "...\n",
        "```\n",
        "\n",
        "Đoạn code dưới đây được sử dụng để đọc dữ liệu theo format trên:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B1HR4YOwXXln"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "helper = GoogleTranslator(source=\"english\", target=\"vietnamese\")\n",
        "\n",
        "dps = []\n",
        "dp = None\n",
        "for line in file_lines:\n",
        "    if line[0] == \"#\":\n",
        "        if dp:\n",
        "            dp['solution'] = ''.join(dp['solution'])\n",
        "            dps.append(dp)\n",
        "        dp = {\"question\": None, \"solution\": []}\n",
        "        idx = 1\n",
        "        # Vì trong dữ liệu có một số câu hỏi có số thứ tự ở đầu\n",
        "        # Vòng for sau để loại bỏ những số thứ tự đó\n",
        "        for i in range(1, len(line)):\n",
        "            if line[i].isalpha():\n",
        "                idx = i\n",
        "                break\n",
        "        dp['question'] = line[i:].strip()\n",
        "        # dp['question'] = helper.translate(line[i:].strip()) # Dịch câu hỏi sang TV\n",
        "    else:\n",
        "        dp[\"solution\"].append(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ví dụ bộ dữ liệu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Câu hỏi:  viết chương trình python để cộng hai số\n",
            "Câu trả lời: \n",
            "num1 = 1.5\n",
            "num2 = 6.3\n",
            "sum = num1 + num2\n",
            "print(f'Sum: {sum}')\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Câu hỏi: \", dps[0][\"question\"])\n",
        "print(\"Câu trả lời: \")\n",
        "print(dps[0][\"solution\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA-1MuOecZRt",
        "outputId": "fcf5ae3e-5417-4b77-917a-f05859a56659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kích cỡ của dữ liệu: 4050\n"
          ]
        }
      ],
      "source": [
        "print(\"Kích cỡ của dữ liệu:\", len(dps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lưu bộ dữ liệu dưới dạng .csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "python_problems_df = pd.DataFrame(dps)\n",
        "# python_problems_df.to_csv(\"vi_to_code.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# python_problems_df = pd.read_csv(\"vi_to_code.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swBfwcDaXEh5"
      },
      "source": [
        "## Tạo một tokenizer để sử dụng với code Python\n",
        "\n",
        "Python là một ngôn ngữ lập trình với cấu trúc riêng của nó. Một số tokenizer có sẵn sẽ không tối ưu. Ta sẽ xây dựng một tokenizer tùy biến phù hợp sử dụng thư viện tokenizer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nsoc0eCpb8e"
      },
      "source": [
        "Để tăng kích thước dữ liệu, khi tạo token cho mã python ta sẽ ẩn ngẫu nhiên một tên một số biến để mô hình khi được huấn luyện không quá tập trung vào cách đặt tên biến mà thực sự cố gắng để hiểu cú pháp và logic của đoạn code\n",
        "\n",
        "Trong quá trình chọn đấy, cần bỏ qua các từ khóa của Python như: range, enumerate, ord, int, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rbIMyrYapfwS"
      },
      "outputs": [],
      "source": [
        "from tokenize import tokenize, untokenize\n",
        "import keyword\n",
        "\n",
        "def augment_tokenize_python_code(python_code_str, mask_factor=0.3):\n",
        "\n",
        "\n",
        "    var_dict = {} # Dictionary that stores masked variables\n",
        "\n",
        "    # certain reserved words that should not be treated as normal variables and\n",
        "    # hence need to be skipped from our variable mask augmentations\n",
        "    skip_list = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'zip'\n",
        "                 'char', 'list', 'dict', 'tuple', 'set', 'len', 'sum', 'min', 'max']\n",
        "    skip_list.extend(keyword.kwlist)\n",
        "\n",
        "    var_counter = 1\n",
        "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\n",
        "    tokenized_output = []\n",
        "\n",
        "    for i in range(0, len(python_tokens)):\n",
        "      if python_tokens[i].type == 1 and python_tokens[i].string not in skip_list:\n",
        "        \n",
        "        if i>0 and python_tokens[i-1].string in ['def', '.', 'import', 'raise', 'except', 'class']: # avoid masking modules, functions and error literals\n",
        "          skip_list.append(python_tokens[i].string)\n",
        "          tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "        elif python_tokens[i].string in var_dict:  # if variable is already masked\n",
        "          tokenized_output.append((python_tokens[i].type, var_dict[python_tokens[i].string]))\n",
        "        elif random.uniform(0, 1) > 1-mask_factor: # randomly mask variables\n",
        "          var_dict[python_tokens[i].string] = 'var_' + str(var_counter)\n",
        "          var_counter+=1\n",
        "          tokenized_output.append((python_tokens[i].type, var_dict[python_tokens[i].string]))\n",
        "        else:\n",
        "          skip_list.append(python_tokens[i].string)\n",
        "          tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "      \n",
        "      else:\n",
        "        tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\n",
        "    \n",
        "    return tokenized_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shdWBNLu0DkK"
      },
      "source": [
        "## Chia tập dữ liệu thành training set và validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5cdHbscZsSJu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "msk = np.random.rand(len(python_problems_df)) < 0.85 # 85% training còn lại là validation\n",
        "\n",
        "train_df = python_problems_df[msk]\n",
        "val_df = python_problems_df[~msk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDtZSkLUu53D",
        "outputId": "a332b531-f0f2-4da7-b09c-0d09f3fd24cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3424, 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3SkbK0Qu9TZ",
        "outputId": "e5108fb5-fdb8-489f-ef92-d7f59ee5799c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(626, 2)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u7EyiRZ6brX"
      },
      "source": [
        "## Tạo vocabulary sử dụng thư viện torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PlIi4zsLKwLE"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "dLID_2ZtixKY"
      },
      "outputs": [],
      "source": [
        "Input = data.Field(tokenize = 'spacy',\n",
        "            init_token='<sos>', \n",
        "            eos_token='<eos>', \n",
        "            lower=True)\n",
        "\n",
        "Output = data.Field(tokenize = augment_tokenize_python_code,\n",
        "                    init_token='<sos>', \n",
        "                    eos_token='<eos>', \n",
        "                    lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ttEpbc2rixPx"
      },
      "outputs": [],
      "source": [
        "fields = [('Input', Input),('Output', Output)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxsyNTBtogcD"
      },
      "source": [
        "Việc tăng kích thước dữ liệu có thể tăng vốn từ vựng vượt xa mức ban đầu. Do đó cần kiểm soát càng nhiều biến thể càng tốt. Đoạn code dưới đây áp dụng tăng cường dữ liệu 100 lần"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uP_yJeqjoLLV"
      },
      "outputs": [],
      "source": [
        "train_example = []\n",
        "val_example = []\n",
        "\n",
        "train_expansion_factor = 100\n",
        "for j in range(train_expansion_factor):\n",
        "  for i in range(train_df.shape[0]):\n",
        "      try:\n",
        "          ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\n",
        "          train_example.append(ex)\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "for i in range(val_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\n",
        "        val_example.append(ex)\n",
        "    except:\n",
        "        pass       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ooT2EqpmtcAW"
      },
      "outputs": [],
      "source": [
        "train_data = data.Dataset(train_example, fields)\n",
        "valid_data =  data.Dataset(val_example, fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Uk4zu6Ntqgfr"
      },
      "outputs": [],
      "source": [
        "Input.build_vocab(train_data, min_freq = 0)\n",
        "Output.build_vocab(train_data, min_freq = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lưu lại để sử dụng sau này\n",
        "torch.save(Input, \"src.pt\")\n",
        "torch.save(Output, \"trg.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njS_msug6eQ3"
      },
      "source": [
        "# Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd-C0ntd8x1e"
      },
      "source": [
        "Mô hình Transformer có ba thành phần chính:\n",
        "\n",
        "1. Encoder chuyển đổi một chuỗi đầu vào thành các vector biểu diễn trạng thái.\n",
        "2. Cơ chế Attention cho phép mô hình Transformer ập trung vào các khía cạnh phù hợp của dòng đầu vào tuần tự. Điều này được sử dụng lặp lại trong cả encoder và deocder để giúp chúng lập ngữ cảnh dữ liệu đầu vào.\n",
        "3. Decoder chuyển đổi vector biểu diễn trạng thái để tạo ra chuỗi đầu ra mục tiêu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSjhBKP59ntL"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgvD_MpkC2OS"
      },
      "source": [
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-encoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQYN9WDA9Hh_"
      },
      "source": [
        "Encoder nhận một batch các chuỗi nguồn và mặt nạ chuỗi làm đầu vào. Mặt nạ nguồn chứa giá trị 1 tại các vị trí mà chuỗi đầu vào có các giá trị hợp lệ và 0 tại các vị trí mà chuỗi đầu vào có các giá trị <pad>. Điều này đảm bảo rằng cơ chế chú ý trong bộ mã hóa không chú ý đến các giá trị <pad>.\n",
        "\n",
        "Ta chuyển đổi các mã thông báo chuỗi nguồn của chúng tôi thành các embedding ('tok_embedding') có độ dài 'hid_dim'. Vì ta không sử dụng bất kỳ mạng tuần tự nào, ta cần gán một thẻ cho mỗi mã thông báo với các chỉ số vị trí của nó để bảo toàn thông tin tuần tự. Ta tạo ra một tensor chỉ số (tức là 'pos') và chuyển đổi nó thành một embedding ('pos_embedding') có độ dài 'hid_dim'. Điều này được kết hợp với các chuỗi nguồn embedding để tạo ra tensor đầu vào ban đầu, được gọi là src. Tensor src này được truyền qua một loạt các Encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NE6JimgOCz-w"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1E12pQr9REU"
      },
      "source": [
        "EncoderLayer là khối xây dựng cơ bản của thành phần Mã hóa trong Transformer. Tensor src cùng với 'src_mask' của nó được đưa vào một hoạt động Multihead-self-attention để giúp mô hình của ta tập trung vào các khía cạnh cần thiết của tensor src. Đầu ra từ quá trình này được kết hợp với tensor src và được chuẩn hóa để tránh vanishing/exploding gradients (trong quá trình huấn luyện). Đầu ra kết hợp này được đưa vào Một lớp PosiionwiseFeedForward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2LheiXWVFDEg"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h_Iqnk4Jg5k"
      },
      "source": [
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-attention.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjEVmTzG9uZ4"
      },
      "source": [
        "PositionwiseFeedForwardLayer tiếp tục xử lý đầu vào kết hợp bằng cách sử dụng hai lớp kết nối đầy đủ và một hàm kích hoạt Relu giữa chúng. Kết hợp này với nhúng src là đầu ra cuối cùng của một encoder. Quá trình này lặp lại cho mỗi khối encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R9w9xDUKL7LU"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VroGxzNo-GGI"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3MtR2yd-Iaz"
      },
      "source": [
        "Attention là một cơ chế cho phép một mô hình tập trung vào các phần cần thiết của chuỗi đầu vào theo yêu cầu của nhiệm vụ đang xử lý."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZZmeHfGhGzkN"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBFqGg5z-o_r"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbTr7YPSMRpC"
      },
      "source": [
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-decoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaHaOGNm_Isc"
      },
      "source": [
        "Kiến trúc của một decoder rất giống với của encoder với những khác biệt đáng kể xuất phát từ sự hiện diện của đầu vào từ hai nguồn, chuỗi mục tiêu và vector biểu diễn trạng thái từ bộ mã hóa. Giống như cách chúng ta có một khối EncoderLayer cho Encoder, chúng ta sẽ có một DecoderLayer nhận đầu vào là sự kết hợp của nhúng từ chuỗi mã thông báo mục tiêu (tok_embedding) và nhúng của các chỉ số vị trí cho những mã thông báo này. Và như đã đề cập trước đó, đầu ra của bộ mã hóa cũng hoạt động như một trong các đầu vào của DecoderLayer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iWBMMF45MMNS"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 10000):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcK1-4qZ_WBM"
      },
      "source": [
        "Mỗi DecoderLayer bao gồm hai hoạt động chú ý:\n",
        "\n",
        "1. Tự chú ý đến embedding trg.\n",
        "2. Quá trình Multi-head attention sử dụng trg như là vector truy vấn và đầu ra của bộ mã hóa hoạt động như là các vector key và value.\n",
        "\n",
        "Sự hiện diện của một  Multi-head attention bổ sung phân biệt DecoderLayer mã so với EncoderLayer.\n",
        "\n",
        "Các đầu ra chú ý từ self-attention được chuẩn hóa và kết hợp với embedding trg bằng một kết nối dư. Sau đó, điều này được gửi vào hoạt động chú ý đa đầu cùng với đầu ra của bộ mã hóa. Các đầu ra của lớp chú ý sau đó được kết hợp với đầu vào trg một lần nữa và chuẩn hóa trước khi được gửi vào lớp feedforward theo vị trí để tạo ra các đầu ra cuối cùng của Lớp Mã giải mã.\n",
        "\n",
        "Mục đích của tất cả các hoạt động chuẩn hóa là để ngăn vanishing/exploding gradients trong quá trình huấn luyện."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CMEr1IFUMxco"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udpPhQ2UN8oQ"
      },
      "source": [
        "Dưới đây mô hình transformer cho các vấn đề seq2seq."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Dr3Mg8OGN6ul"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvrK6zbF_2Fs"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Kiểm tra xem GPU có khả dụng không"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\SeminarDS\\CodeGeneratorProject\\.venv\\lib\\site-packages\\torchtext\\data\\utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
          ]
        }
      ],
      "source": [
        "Input = torch.load(\"src.pt\")\n",
        "Output = torch.load(\"trg.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4zsZjSSWOSHc"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(Input.vocab)\n",
        "OUTPUT_DIM = len(Output.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 16\n",
        "DEC_HEADS = 16\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3vG-tI737e6",
        "outputId": "67f5f267-5b3e-40e3-80b8-da8b818c759a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Output.vocab.__dict__['freqs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "iYVZYDVcOUGK"
      },
      "outputs": [],
      "source": [
        "SRC_PAD_IDX = Input.vocab.stoi[Input.pad_token]\n",
        "TRG_PAD_IDX = Output.vocab.stoi[Output.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd0ePzj0OzLa",
        "outputId": "75e4ffdb-e5fb-4c9b-ba35-5c59d62868ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 6,772,740 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fmZ0hyo8O0vE"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NRtAM9Y4O2N2"
      },
      "outputs": [],
      "source": [
        "model.apply(initialize_weights);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "NEpApG3YO3ZE"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95cvaGRg_-Ml"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs2XdrveCtDD"
      },
      "source": [
        "Ta đã sử dụng các biến đổi trong tập dữ liệu để che giấu các biến. Điều này có nghĩa là mô hình của ta có thể dự đoán một loạt các giá trị cho một biến cụ thể và tất cả chúng đều đúng miễn là các dự đoán đó nhất quán thông qua mã. Điều này có nghĩa là nhãn huấn luyện của chúng tôi không chắc chắn lắm và do đó sẽ hợp lý hơn nếu xem xét chúng là chính xác với xác suất 1- smooth_eps và không chính xác trong trường hợp khác. Đây là điều mà việc label smoothening cho phép ta thực hiện được. Dưới đây là code triển khai của CrossEntropyLoss với việc label smoothening."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NNfxmsLxD7yb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CrossEntropyLoss(nn.CrossEntropyLoss):\n",
        "    \"\"\"CrossEntropyLoss - with ability to recieve distrbution as targets, and optional label smoothing\"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, ignore_index=-100, reduction='mean', smooth_eps=None, smooth_dist=None, from_logits=True):\n",
        "        super(CrossEntropyLoss, self).__init__(weight=weight,\n",
        "                                               ignore_index=ignore_index, reduction=reduction)\n",
        "        self.smooth_eps = smooth_eps\n",
        "        self.smooth_dist = smooth_dist\n",
        "        self.from_logits = from_logits\n",
        "\n",
        "    def forward(self, input, target, smooth_dist=None):\n",
        "        if smooth_dist is None:\n",
        "            smooth_dist = self.smooth_dist\n",
        "        return cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index,\n",
        "                             reduction=self.reduction, smooth_eps=self.smooth_eps,\n",
        "                             smooth_dist=smooth_dist, from_logits=self.from_logits)\n",
        "\n",
        "\n",
        "def cross_entropy(inputs, target, weight=None, ignore_index=-100, reduction='mean',\n",
        "                  smooth_eps=None, smooth_dist=None, from_logits=True):\n",
        "    \"\"\"cross entropy loss, with support for target distributions and label smoothing https://arxiv.org/abs/1512.00567\"\"\"\n",
        "    smooth_eps = smooth_eps or 0\n",
        "\n",
        "    # ordinary log-liklihood - use cross_entropy from nn\n",
        "    if _is_long(target) and smooth_eps == 0:\n",
        "        if from_logits:\n",
        "            return F.cross_entropy(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\n",
        "        else:\n",
        "            return F.nll_loss(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\n",
        "\n",
        "    if from_logits:\n",
        "        # log-softmax of inputs\n",
        "        lsm = F.log_softmax(inputs, dim=-1)\n",
        "    else:\n",
        "        lsm = inputs\n",
        "\n",
        "    masked_indices = None\n",
        "    num_classes = inputs.size(-1)\n",
        "\n",
        "    if _is_long(target) and ignore_index >= 0:\n",
        "        masked_indices = target.eq(ignore_index)\n",
        "\n",
        "    if smooth_eps > 0 and smooth_dist is not None:\n",
        "        if _is_long(target):\n",
        "            target = onehot(target, num_classes).type_as(inputs)\n",
        "        if smooth_dist.dim() < target.dim():\n",
        "            smooth_dist = smooth_dist.unsqueeze(0)\n",
        "        target.lerp_(smooth_dist, smooth_eps)\n",
        "\n",
        "    if weight is not None:\n",
        "        lsm = lsm * weight.unsqueeze(0)\n",
        "\n",
        "    if _is_long(target):\n",
        "        eps_sum = smooth_eps / num_classes\n",
        "        eps_nll = 1. - eps_sum - smooth_eps\n",
        "        likelihood = lsm.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
        "        loss = -(eps_nll * likelihood + eps_sum * lsm.sum(-1))\n",
        "    else:\n",
        "        loss = -(target * lsm).sum(-1)\n",
        "\n",
        "    if masked_indices is not None:\n",
        "        loss.masked_fill_(masked_indices, 0)\n",
        "\n",
        "    if reduction == 'sum':\n",
        "        loss = loss.sum()\n",
        "    elif reduction == 'mean':\n",
        "        if masked_indices is None:\n",
        "            loss = loss.mean()\n",
        "        else:\n",
        "            loss = loss.sum() / float(loss.size(0) - masked_indices.sum())\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def onehot(indexes, N=None, ignore_index=None):\n",
        "    \"\"\"\n",
        "    Creates a one-representation of indexes with N possible entries\n",
        "    if N is not specified, it will suit the maximum index appearing.\n",
        "    indexes is a long-tensor of indexes\n",
        "    ignore_index will be zero in onehot representation\n",
        "    \"\"\"\n",
        "    if N is None:\n",
        "        N = indexes.max() + 1\n",
        "    sz = list(indexes.size())\n",
        "    output = indexes.new().byte().resize_(*sz, N).zero_()\n",
        "    output.scatter_(-1, indexes.unsqueeze(-1), 1)\n",
        "    if ignore_index is not None and ignore_index >= 0:\n",
        "        output.masked_fill_(indexes.eq(ignore_index).unsqueeze(-1), 0)\n",
        "    return output\n",
        "\n",
        "def _is_long(x):\n",
        "    if hasattr(x, 'data'):\n",
        "        x = x.data\n",
        "    return isinstance(x, torch.LongTensor) or isinstance(x, torch.cuda.LongTensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RnWtafKlAhb_"
      },
      "outputs": [],
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    # print(inp.shape, target.shape, mask.sum())\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = CrossEntropyLoss(ignore_index = TRG_PAD_IDX, smooth_eps=0.20)\n",
        "    loss = crossEntropy(inp, target)\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "n9Dy_wWrO46l"
      },
      "outputs": [],
      "source": [
        "criterion = maskNLLLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQGdcEFmAxlO"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itmoGDi_tN74"
      },
      "source": [
        "Để áp dụng lại các biến đổi dữ liệu theo cách khác nhau trong mỗi epoch, chúng tôi tái tạo tập dữ liệu và trình tải dữ liệu ở đầu mỗi epoch. Điều này làm cho quá trình huấn luyện được điều chỉnh đều đặn và giúp ta tạo ra các mô hình tốt hơn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ycBBiEpuO6cG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def make_trg_mask(trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != TRG_PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    n_totals = 0\n",
        "    print_losses = []\n",
        "    for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
        "        # print(batch)\n",
        "        loss = 0\n",
        "        src = batch.Input.permute(1, 0)\n",
        "        trg = batch.Output.permute(1, 0)\n",
        "        trg_mask = make_trg_mask(trg)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        mask_loss, nTotal = criterion(output, trg, trg_mask)\n",
        "        \n",
        "        mask_loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        print_losses.append(mask_loss.item() * nTotal)\n",
        "        n_totals += nTotal\n",
        "\n",
        "\n",
        "        \n",
        "    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "zi3Ev8gaO79_"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    n_totals = 0\n",
        "    print_losses = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
        "\n",
        "            src = batch.Input.permute(1, 0)\n",
        "            trg = batch.Output.permute(1, 0)\n",
        "            trg_mask = make_trg_mask(trg)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            mask_loss, nTotal = criterion(output, trg, trg_mask)\n",
        "\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "        \n",
        "    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "JuB4JqQRO9Wg"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aax76Ie4O_Cr",
        "outputId": "fbc1062f-f4d9-4ff4-887f-a365835c3de6"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "train_losssss = []\n",
        "val_losssss = []\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_example = []\n",
        "    val_example = []\n",
        "\n",
        "    for i in range(train_df.shape[0]):\n",
        "        try:\n",
        "            ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\n",
        "            train_example.append(ex)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for i in range(val_df.shape[0]):\n",
        "        try:\n",
        "            ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\n",
        "            val_example.append(ex)\n",
        "        except:\n",
        "            pass       \n",
        "\n",
        "    train_data = data.Dataset(train_example, fields)\n",
        "    valid_data =  data.Dataset(val_example, fields)\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "    train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), batch_size = BATCH_SIZE, \n",
        "                                                                sort_key = lambda x: len(x.Input),\n",
        "                                                                sort_within_batch=True, device = device)\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    train_losssss.append(train_loss)\n",
        "    val_losssss.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model1.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3_aq7QTPBFc",
        "outputId": "e8bdc0e6-cd7e-4d5e-bb92-1029c59ef9d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "English to Python.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
